[
  {
    "objectID": "projects/cyclistic/cyclistic.html",
    "href": "projects/cyclistic/cyclistic.html",
    "title": "Cyclistic Customer Analysis",
    "section": "",
    "text": "Defining the business task\nThe scope of this analysis is limited to the first step, and investigates the question:\n\nHow do annual members and casual riders use Cyclistic bikes differently?\n\nUnpacking this question highlights a number of areas that may provide useful insights.\nWhat defines a member and a casual rider?\nThe Divvy Bikes pricing information indicates members pay an upfront annual fee to access pricing that includes “no-charge” ride time and lower per minute charges. Casual riders access ride sharing on an ad-hoc basis, paying a per-ride charge, and higher per minute charge which begins when the bike is undocked. Daily pass riders pay a day access fee to access unlimited 3 hour rides for the duration of the pass.\nWhat influence do the plans have on the user behaviour? Can we distinguish plan types by the average duration of rides? What percentage of riders exceed the included 45 minutes ride time of membership plans? Is this same for members and casuals?\nThis may help identify if time inclusions are a factor for casual riders considering membership.\nAnother important aspect to consider is when different user cohorts ride. Which days, and times are popular for the different cohorts? And is there identifiable differences or commonality in behaviours?\nAre the types and number of rides influenced by day to day variations in weather or broader seasonal patterns? Are causals user all season, or fair weather riders. All season casual riders could be a group that see benefit in membership.\nWhere do different user cohorts ride? Riders commuting to work are likely to use docking stations in business districts during the week. Recreational riders may prefer parks and areas along the shoreline or cafe precincts. Docking stations with high levels of usage on different days of the week may provide insight into where user hotspots are located.\n\n\nData sources\n\nDivvy Bikes system data and pricing\nThe base data for individual rides was extracted from Divvy Bike data files covering the period 1 September 2021 to 31 August 2022. Additional data description and a download link is provided on the Divvy Bikes system data page.\nThe license allows inclusion of data within analyses and studies published for non-commercial. This clause covers the intended use.\nDetails of current pricing for Divvy Bikes offerings was accessed on 25 September 2022.\n\n\nNOAA Climate Data\nWeather data covering September 2021 to August 2022 ordered from NOOA National Centers for Environmental Information\nO’Hare International Airport weather station was selected as representative of the Chicago region.\n\n\nDivvy Bikes historical station status\nHistorical station status identifies which stations actively used between September 2021 and August 2022. This information is used to assist identifying Divvy operational rides in the data set.\nCity of Chicago open data listing of Divvy Stations\n\n\n\nData cleaning and preparation\n\nInitial import\n\n\n\nThe Divvy trip data files have a consistent naming format YYYYMM-divvy-tripdata.zip. This allows file names to be generated for months in the range September 2021 to August 2022.\n\n\n\n01_import_clean.R\n\ndivvy_files <- seq(\n  my(params$start_date),\n  my(params$end_date),\n  by = \"months\"\n) %>%\n  enframe(\n    value = \"timestamp\"\n  ) %>%\n  glue_data(\n    \"{year(timestamp)}\",\n    \"{stringi::stri_sprintf('%02d', month(timestamp))}\",\n    \"-divvy-tripdata.zip\"\n  )\n\n\nTo preserve a local copy of the original data, zip files are downloaded to the data/raw folder. The folder is checked each time the script is run, and files which are already present are removed from the download list.\n\ndivvy_downloaded <- glue(\"data/raw/{divvy_files}\")\nto_dl <- divvy_files[!file.exists(divvy_downloaded)]\n\nAny files which are not present in data/raw are downloaded.\n\nif (length(to_dl) > 0) {\n  download.file(\n    glue(\"https://divvy-tripdata.s3.amazonaws.com/{to_dl}\"),\n    glue(\"data/raw/{to_dl}\")\n  )\n}\n\nNote that the preceding section will not execute correctly in a Quarto document. A script for the full import process can be found in the Github repository.\nTo check the downloaded file data, the first 1000 rows are read from September 2021 zip file. read_csv uses the first 1000 rows to determine the type of data in each column. The guessed column type specification is inspected with the spec function.\n\nbike_inspect <- map_dfr(\n  divvy_downloaded[1],\n  ~ archive_read(.) %>%\n    read_csv(\n      n_max = 1000,\n      show_col_types = FALSE\n    )\n)\nspec(bike_inspect)\n\ncols(\n  ride_id = col_character(),\n  rideable_type = col_character(),\n  started_at = col_datetime(format = \"\"),\n  ended_at = col_datetime(format = \"\"),\n  start_station_name = col_character(),\n  start_station_id = col_character(),\n  end_station_name = col_character(),\n  end_station_id = col_character(),\n  start_lat = col_double(),\n  start_lng = col_double(),\n  end_lat = col_double(),\n  end_lng = col_double(),\n  member_casual = col_character()\n)\n\n\nTo verify column naming is consistent across all files, the header row from each file is read. The resulting data frame is checked with distinct(). If all headers are identical the result is a dataframe with a single row.\n\nbike_headers <- map_dfr(\n  divvy_downloaded,\n  ~ archive_read(.) %>%\n    read_csv(\n      n_max = 1,\n      col_names = FALSE,\n      show_col_types = FALSE\n    )\n) %>%\n  distinct()\n\nstr(bike_headers)\n\ntibble [1 × 13] (S3: tbl_df/tbl/data.frame)\n $ X1 : chr \"ride_id\"\n $ X2 : chr \"rideable_type\"\n $ X3 : chr \"started_at\"\n $ X4 : chr \"ended_at\"\n $ X5 : chr \"start_station_name\"\n $ X6 : chr \"start_station_id\"\n $ X7 : chr \"end_station_name\"\n $ X8 : chr \"end_station_id\"\n $ X9 : chr \"start_lat\"\n $ X10: chr \"start_lng\"\n $ X11: chr \"end_lat\"\n $ X12: chr \"end_lng\"\n $ X13: chr \"member_casual\"\n\n\nAfter verifying the detected formats, and checking column naming is consistent across all files, the full dataset can be imported. Passing the full column specification to read_csv() ensure that data which does not match the expected type is flagged as a problem. Issues that arise while importing data can be examined using the problems() function.\n\nbike_rides <- map_dfr(\n  divvy_downloaded,\n  ~ archive_read(.) %>%\n    read_csv(\n      col_types = cols(\n        ride_id = col_character(),\n        rideable_type = col_factor(levels = c(\n          \"classic_bike\",\n          \"docked_bike\",\n          \"electric_bike\"\n        )),\n        started_at = col_datetime(),\n        ended_at = col_datetime(),\n        start_station_name = col_character(),\n        start_station_id = col_character(),\n        end_station_name = col_character(),\n        end_station_id = col_character(),\n        start_lat = col_double(),\n        start_lng = col_double(),\n        end_lat = col_double(),\n        end_lng = col_double(),\n        member_casual = col_factor(levels = c(\n          \"member\",\n          \"casual\"\n        ))\n      ),\n      locale = locale(tz = \"America/Chicago\")\n    )\n)\n\n\n\nData inspection\n\nbike_rides %>%\n  summarise(across(\n    everything(),\n    ~ sum(is.na(.x))\n  )) %>%\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Missing Count\"\n  )\n\n\n\n\nTable 1: Missing Values\n\n\nColumn\nMissing Count\n\n\n\n\nride_id\n0\n\n\nrideable_type\n0\n\n\nstarted_at\n0\n\n\nended_at\n0\n\n\nstart_station_name\n884365\n\n\nstart_station_id\n884363\n\n\nend_station_name\n946303\n\n\nend_station_id\n946303\n\n\nstart_lat\n0\n\n\nstart_lng\n0\n\n\nend_lat\n5727\n\n\nend_lng\n5727\n\n\nmember_casual\n0\n\n\n\n\n\n\n\n\nbike_rides %>%\n  mutate(\n    missing_start = is.na(start_station_name),\n    missing_end = is.na(end_station_name)\n  ) %>%\n  summarise(\n    \"Start Only\" = sum(missing_start & !missing_end),\n    \"End Only\" = sum(missing_end & !missing_start),\n    Both = sum(missing_start & missing_end),\n    \"Rides effected\" = sum(missing_start | missing_end)\n  )\n\n\n\n\nTable 2: Missing Values by station type\n\n\nStart Only\nEnd Only\nBoth\nRides effected\n\n\n\n\n376594\n438532\n507771\n1322897\n\n\n\n\n\n\n\nTable 2 indicates that 22.49% of all rides are missing data for least one docking stations. This represents significant number of data points, and should be checked to determine whether this is an error or there has been systematic changes made.\n\nbike_rides %>%\n  summarise(\n    start_lat = range(start_lat, na.rm = TRUE),\n    start_lng = range(start_lng, na.rm = TRUE),\n    end_lat = range(end_lat, na.rm = TRUE),\n    end_lng = range(end_lng, na.rm = TRUE)\n  )\n\n\n\n\nTable 3: Latitude and Longitude ranges\n\n\nstart_lat\nstart_lng\nend_lat\nend_lng\n\n\n\n\n41.64000\n-87.84000\n41.39\n-88.97\n\n\n45.63503\n-73.79648\n42.37\n-87.50\n\n\n\n\n\n\n\nThe maximum start longitude and latitude values listed in Table 3 are significantly different to the remaining values. This suggests some rides may have originated outside the Chicago metropolitan area serviced by Cyclistic.\n\n\n\n\n\nTable 4: Clipped coordinates and missing start station name\n\n\nMissing\nLatitude\nLongitude\n\n\n\n\nFALSE\n78535\n78530\n\n\nTRUE\n884363\n884363\n\n\n\n\n\n\n\n\n\n\n\n\nTable 5: Clipped coordinates and missing end station name\n\n\nMissing\nLatitude\nLongitude\n\n\n\n\nFALSE\n71004\n71002\n\n\nTRUE\n940576\n940576\n\n\n\n\n\n\n\nIt appears that some latitude and longitude values may have been rounded to two significant digits. Comparing the value to itself rounded to 2 decimal places identifies potentially truncated values. Clamping the coordinates in this way means actual locations can be anywhere within 1 square kilometre centred on the given grid location.\nNotably all start stations with missing names also have rounded coordinates. The total of ends stations with missing latitude and longitude and those with rounded coordinates matches the count of missing end station names.\nThis suggests that there is a systemic reason for the missing data, rather than error. The data may have been anonymised to protect riders privacy. This needs to be checked with Cyclistics data collection team.\nThe ride duration and other information appears plausible and the lack of location data does not impact ride count, or duration. These records can be retained but filtered for any analysis which depends on accurate location.\nWhile the majority of rounded coordinates occur where station names are missing approximately 8% are for stations which are named.\n\nbike_rides %>%\n  summarise(\n    start_range = range(started_at),\n    end_range = range(ended_at)\n  )\n\n\n\n\nTable 6: Ride start and end date ranges\n\n\nstart_range\nend_range\n\n\n\n\n2021-09-01 00:00:06\n2021-09-01 00:00:41\n\n\n2022-08-31 23:59:39\n2022-09-06 21:49:04\n\n\n\n\n\n\n\nTable 6 indicates the dataset includes rides which finished after August 2022.\n\n\n\nIn total 6431 rides are active at midnight on 31 August 2022. Of these, 48 rides are still active at 9.00am on 1 September 2022. As these overnight rides are excluded from the start of the data set, I’ve opted to retain rides which completed prior to 9.00am to ensure this group of riders is not under represented.\n\n\nData Cleaning"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Google Data Analytics Certificate Capstone\n\n\nAn analysis of historical Divvy Bikes ride data to identify differences in user cohort behaviour.\n\n\n\n\n\n\nOct 1, 2022\n\n\n\n\n\n\nNo matching items"
  }
]