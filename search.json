[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Google Data Analytics Certificate Capstone\n\n\n\n\n\n\n\n\n\nSep 23, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/cyclistic/cyclistic.html",
    "href": "projects/cyclistic/cyclistic.html",
    "title": "Cyclistic Customer Analysis",
    "section": "",
    "text": "This analysis examines the question:\n\nHow do annual members and casual riders use Cyclistic bikes differently?"
  },
  {
    "objectID": "projects/cyclistic/cyclistic.html#data-sources",
    "href": "projects/cyclistic/cyclistic.html#data-sources",
    "title": "Cyclistic Customer Analysis",
    "section": "Data sources",
    "text": "Data sources\nThree primary data sources were used for the analysis:\n\nDivvy Bikes ride data\nMonthly data files from September 2021 to August 2022. Additional data description and download link can be found on the system data page.\nDivvy Bikes website\nDetails of time limits and charges for current casual and membership plans.\nDivvy Bikes active stations\n\nhttps://data.cityofchicago.org/Transportation/Divvy-Bicycle-Stations/bbyy-e7gq\n\nNOAA Daily weather records\nWeather data covering September 2021 to August 2022.\nO’Hare International Airport weather station was selected as representative of the Chicago region."
  },
  {
    "objectID": "projects/cyclistic/cyclistic.html#data-cleaning-and-preparation",
    "href": "projects/cyclistic/cyclistic.html#data-cleaning-and-preparation",
    "title": "Cyclistic Customer Analysis",
    "section": "Data cleaning and preparation",
    "text": "Data cleaning and preparation\n\nInitial import\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(glue)\nlibrary(archive)\n\nThe Divvy trip data files have a consistent naming format prefixed with numeric year and month. A list of data file names is generated for months in the range start_date to end_date.\n\n\n\n01_import_clean.R\n\nstart_date <- \"2021-09\"\nend_date <- \"2022-08\"\n\ndivvy_files <- seq(\n  ym(start_date),\n  ym(end_date),\n  by = \"months\"\n) %>%\n  enframe(\n    value = \"timestamp\"\n  ) %>%\n  glue_data(\n    \"{year(timestamp)}\",\n    \"{stringi::stri_sprintf('%02d', month(timestamp))}\",\n    \"-divvy-tripdata.zip\"\n  )\n\n\nAll original zip files are downloaded to the divy_data/raw folder to ensure there is an unmodified copy of the data. Any files that are already present are not download again.\n\ndivvy_downloaded <- glue(\"divy_data/raw/{divvy_files}\")\nto_dl <- divvy_files[!file.exists(divvy_downloaded)]\n\nRequired data files that are missing from the raw data folder are downloaded.\n\nif (length(to_dl) > 0) {\n  download.file(\n    glue(\"https://divvy-tripdata.s3.amazonaws.com/{to_dl}\"),\n    glue(\"data/raw/{to_dl}\")\n  )\n}\n\nNote that the preceding section will not execute correctly in a Quarto document. A script for the full import process is provided in the supporting material.\nTo check the downloaded file data, 1000 rows are read from the oldest file and column specification inspected.\n\nbike_inspect <- map_dfr(\n  divvy_downloaded[1],\n  ~ archive_read(.) %>%\n    read_csv(\n      n_max = 1000,\n      show_col_types = FALSE\n    )\n)\nspec(bike_inspect)\n\ncols(\n  ride_id = col_character(),\n  rideable_type = col_character(),\n  started_at = col_datetime(format = \"\"),\n  ended_at = col_datetime(format = \"\"),\n  start_station_name = col_character(),\n  start_station_id = col_character(),\n  end_station_name = col_character(),\n  end_station_id = col_character(),\n  start_lat = col_double(),\n  start_lng = col_double(),\n  end_lat = col_double(),\n  end_lng = col_double(),\n  member_casual = col_character()\n)\n\n\nThe first row from all data files is read to check for consistent naming and columns.\n\nbike_headers <- map_dfr(\n  divvy_downloaded,\n  ~ archive_read(.) %>%\n    read_csv(\n      id = \"filename\",\n      n_max = 1,\n      col_names = FALSE,\n      show_col_types = FALSE\n    )\n) %>%\n  select(-filename) %>%\n  distinct()\n\nknitr::kable(bike_headers)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX1\nX2\nX3\nX4\nX5\nX6\nX7\nX8\nX9\nX10\nX11\nX12\nX13\n\n\n\n\nride_id\nrideable_type\nstarted_at\nended_at\nstart_station_name\nstart_station_id\nend_station_name\nend_station_id\nstart_lat\nstart_lng\nend_lat\nend_lng\nmember_casual\n\n\n\n\n\nAfter checking the detected formats, and ensuring the column naming is consistent across all files, data is read from the zip files using a defined column specification. Data not matching the defined format will raise a warning from the import process.\n\nbike_rides <- map_dfr(\n  divvy_downloaded,\n  ~ archive_read(.) %>%\n    read_csv(\n      col_types = cols(\n        ride_id = col_character(),\n        rideable_type = col_factor(levels = c(\n          \"classic_bike\",\n          \"docked_bike\",\n          \"electric_bike\"\n        )),\n        started_at = col_datetime(),\n        ended_at = col_datetime(),\n        start_station_name = col_character(),\n        start_station_id = col_character(),\n        end_station_name = col_character(),\n        end_station_id = col_character(),\n        start_lat = col_double(),\n        start_lng = col_double(),\n        end_lat = col_double(),\n        end_lng = col_double(),\n        member_casual = col_factor(levels = c(\n          \"member\",\n          \"casual\"\n        ))\n      ),\n      locale = locale(tz = \"America/Chicago\")\n    )\n)\nknitr::kable(slice_sample(bike_rides, n = 10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nride_id\nrideable_type\nstarted_at\nended_at\nstart_station_name\nstart_station_id\nend_station_name\nend_station_id\nstart_lat\nstart_lng\nend_lat\nend_lng\nmember_casual\n\n\n\n\nDB0E5F084D47A9A8\nelectric_bike\n2022-08-19 19:48:09\n2022-08-19 20:03:08\nNA\nNA\nNA\nNA\n41.90000\n-87.66000\n41.91000\n-87.63000\ncasual\n\n\nA023F0B58470C7CB\nclassic_bike\n2021-09-01 20:58:34\n2021-09-01 22:06:16\nSheffield Ave & Willow St\nTA1306000032\nRush St & Cedar St\nKA1504000133\n41.91369\n-87.65286\n41.90231\n-87.62769\nmember\n\n\n3CF8A34FA61D155C\nelectric_bike\n2022-03-14 15:58:36\n2022-03-14 16:09:36\nNA\nNA\nNA\nNA\n41.91000\n-87.71000\n41.92000\n-87.69000\nmember\n\n\n22EFCE15AA2D0936\nclassic_bike\n2021-11-05 13:37:43\n2021-11-05 14:59:25\nCentral Park Ave & Elbridge Ave\n15644\nCentral Park Ave & Elbridge Ave\n15644\n41.93534\n-87.71689\n41.93534\n-87.71689\ncasual\n\n\n180D66CA199C70B5\nelectric_bike\n2021-12-19 22:00:22\n2021-12-19 22:02:46\nBroadway & Sheridan Rd\n13323\nBroadway & Cornelia Ave\n13278\n41.95282\n-87.65007\n41.94553\n-87.64644\nmember\n\n\nE7CCC078116174C0\nelectric_bike\n2022-04-30 13:18:54\n2022-04-30 13:28:49\nWentworth Ave & Cermak Rd\n13075\nShields Ave & 28th Pl\n15443\n41.85309\n-87.63190\n41.84273\n-87.63549\ncasual\n\n\nFB46C45F8A04A70C\ndocked_bike\n2022-08-11 10:03:10\n2022-08-11 10:26:27\nDuSable Lake Shore Dr & North Blvd\nLF-005\nDuSable Lake Shore Dr & Belmont Ave\nTA1309000049\n41.91172\n-87.62680\n41.94078\n-87.63919\ncasual\n\n\n0E05D8ED5FEAFB43\nclassic_bike\n2022-07-04 11:16:29\n2022-07-04 11:22:04\nRavenswood Ave & Lawrence Ave\nTA1309000066\nDamen Ave & Sunnyside Ave\nTA1309000012\n41.96909\n-87.67424\n41.96325\n-87.67926\ncasual\n\n\n2FBCF1A6CE3755EA\nelectric_bike\n2022-02-18 12:34:00\n2022-02-18 12:41:17\nRush St & Superior St\n15530\nSedgwick St & Schiller St\nTA1307000143\n41.89572\n-87.62597\n41.90763\n-87.63857\nmember\n\n\n6ED2E0056EAD585B\nclassic_bike\n2022-01-21 12:27:46\n2022-01-21 12:30:08\nClinton St & Jackson Blvd\n638\nJefferson St & Monroe St\nWL-011\n41.87832\n-87.64098\n41.88033\n-87.64275\nmember\n\n\n\n\n\nThe sample of data shows that some station names and station id’s are missing. The missing stations do have latitude and longitude values, however on closer inspection the values appear to these have been rounded to two decimal places.\nThis suggests that part of the data set may have been anonymised or obfuscated deliberately."
  }
]