[
  {
    "objectID": "projects/cyclistic/cyclistic.html",
    "href": "projects/cyclistic/cyclistic.html",
    "title": "Cyclistic Customer Analysis",
    "section": "",
    "text": "Defining the business task\nThe scope of this analysis is limited to the first step, and investigates the question:\n\nHow do annual members and casual riders use Cyclistic bikes differently?\n\nUnpacking this question highlights a number of areas that may provide useful insights.\n\nWhat defines a member and a casual rider?\nThe Divvy Bikes pricing information indicates members pay an upfront annual fee to access pricing that includes “no-charge” ride time and lower per minute charges. Casual riders access ride sharing on an ad-hoc basis, paying a per-ride charge, and higher per minute charge which begins when the bike is undocked. Daily pass riders pay a day access fee to access unlimited 3 hour rides for the duration of the pass.\n\n\nWhat influence do the plans have on the user behaviour?\nCan we distinguish plan types by the average duration of rides? What percentage of riders exceed the included 45 minutes ride time of membership plans? Is this same for members and casuals?\nThis may help identify if time inclusions are a factor for casual riders considering membership.\n\n\nWhen do different user cohorts ride?\nWhich days, and times are popular for the different cohorts? And are there identifiable differences or commonality in behaviours?\n\n\nDoes weather influence rider behaviour?\nAre the types and number of rides related to day-to-day variations in weather or broader seasonal patterns? Are casual users “all season” or “fair weather” riders? Casual riders who ride around the year could be a group that would find membership attractive.\n\n\nWhere do different user cohorts ride?\nRiders commuting to work are likely to use docking stations in business districts during the week. Recreational riders may prefer parks and areas along the shoreline or cafe precincts. Docking stations with high levels of usage on different days of the week should provide insight into where user hotspots are located.\n\n\n\nData sources\n\nDivvy Bikes system data and pricing\nThe base data for individual rides was extracted from Divvy Bike data files covering the period 1 September 2021 to 31 August 2022. Additional data description and a download link is provided on the Divvy Bikes system data page.\nThe license allows inclusion of data within analyses and studies published for non-commercial. This clause covers the intended use.\nDetails of current pricing for Divvy Bikes offerings was accessed on 25 September 2022.\n\n\nNOAA Climate Data\nWeather data covering September 2021 to August 2022 ordered from NOOA National Centers for Environmental Information\nO’Hare International Airport weather station was selected as representative of the Chicago region.\n\n\nDivvy Bikes historical station status\nHistorical station status identifies which stations actively used between September 2021 and August 2022. This information is used to assist identifying Divvy operational rides in the data set.\nCity of Chicago open data listing of Divvy Stations\n\n\n\nData cleaning and preparation\n\nInitial import\n\n\n\nThe Divvy trip data files have a consistent naming format YYYYMM-divvy-tripdata.zip. This allows file names to be generated for months in the range September 2021 to August 2022.\n\n\nCode\ndivvy_files <- seq(\n  my(params$start_date),\n  my(params$end_date),\n  by = \"months\"\n) %>%\n  enframe(\n    value = \"timestamp\"\n  ) %>%\n  glue_data(\n    \"{year(timestamp)}\",\n    \"{stringi::stri_sprintf('%02d', month(timestamp))}\",\n    \"-divvy-tripdata.zip\"\n  )\n\n\nTo preserve a local copy of the original data, zip files are downloaded to the data/raw folder. The folder is checked each time the script is run, and files which are already present are removed from the download list.\n\n\nCode\ndivvy_downloaded <- glue(\"data/raw/{divvy_files}\")\nto_dl <- divvy_files[!file.exists(divvy_downloaded)]\n\n\nAny files which are not present in the data/rawfolder are downloaded.\n\n\nCode\n# Note that the preceding section will not execute\n# correctly in a Quarto document.\n# A script for the full import process can be found in the\n# Github repository.\n\nif (length(to_dl) > 0) {\n  download.file(\n    glue(\"https://divvy-tripdata.s3.amazonaws.com/{to_dl}\"),\n    glue(\"data/raw/{to_dl}\")\n  )\n}\n\n\nThe first 1000 rows are read from September 2021 zip file. This allows read_csv to determine the type of data in each column. The “guessed” column type specification can then inspected using the spec function.\n\n\nCode\nbike_inspect <- map_dfr(\n  divvy_downloaded[1],\n  ~ archive_read(.) %>%\n    read_csv(\n      n_max = 1000,\n      show_col_types = FALSE\n    )\n)\nspec(bike_inspect)\n\n\ncols(\n  ride_id = col_character(),\n  rideable_type = col_character(),\n  started_at = col_datetime(format = \"\"),\n  ended_at = col_datetime(format = \"\"),\n  start_station_name = col_character(),\n  start_station_id = col_character(),\n  end_station_name = col_character(),\n  end_station_id = col_character(),\n  start_lat = col_double(),\n  start_lng = col_double(),\n  end_lat = col_double(),\n  end_lng = col_double(),\n  member_casual = col_character()\n)\n\n\nThe types defined in the column specification appear to be reasonable choices based on naming of the columns.\nTo verify column naming is consistent across all files, the header row from each file is read. The resulting data frame is processed using distinct() to eliminate duplicated rows. If all headers are identical the resulting data frame will have a single row.\n\n\nCode\nbike_headers <- map_dfr(\n  divvy_downloaded,\n  ~ archive_read(.) %>%\n    read_csv(\n      n_max = 1,\n      col_names = FALSE,\n      show_col_types = FALSE\n    )\n) %>%\n  distinct()\n\nstr(bike_headers)\n\n\ntibble [1 × 13] (S3: tbl_df/tbl/data.frame)\n $ X1 : chr \"ride_id\"\n $ X2 : chr \"rideable_type\"\n $ X3 : chr \"started_at\"\n $ X4 : chr \"ended_at\"\n $ X5 : chr \"start_station_name\"\n $ X6 : chr \"start_station_id\"\n $ X7 : chr \"end_station_name\"\n $ X8 : chr \"end_station_id\"\n $ X9 : chr \"start_lat\"\n $ X10: chr \"start_lng\"\n $ X11: chr \"end_lat\"\n $ X12: chr \"end_lng\"\n $ X13: chr \"member_casual\"\n\n\nAfter verifying the detected formats, and checking column naming is consistent across all files, the full dataset can be imported. Passing the full column specification to read_csv() ensure that data which does not match the expected type is flagged as a problem. Issues that arise while importing data can be examined using the problems() function.\n\n\nCode\nbike_rides <- map_dfr(\n  divvy_downloaded,\n  ~ archive_read(.) %>%\n    read_csv(\n      col_types = cols(\n        ride_id = col_character(),\n        rideable_type = col_factor(levels = c(\n          \"classic_bike\",\n          \"docked_bike\",\n          \"electric_bike\"\n        )),\n        started_at = col_datetime(),\n        ended_at = col_datetime(),\n        start_station_name = col_character(),\n        start_station_id = col_character(),\n        end_station_name = col_character(),\n        end_station_id = col_character(),\n        start_lat = col_double(),\n        start_lng = col_double(),\n        end_lat = col_double(),\n        end_lng = col_double(),\n        member_casual = col_factor(levels = c(\n          \"member\",\n          \"casual\"\n        ))\n      ),\n      locale = locale(tz = \"America/Chicago\")\n    )\n)\n\n\n\n\nData inspection\nWith the data loaded from file, the data structure can checked with glimpse().\n\n\nCode\nbike_rides %>%\n  glimpse()\n\n\nRows: 5,883,043\nColumns: 13\n$ ride_id            <chr> \"9DC7B962304CBFD8\", \"F930E2C6872D6B32\", \"6EF7213790…\n$ rideable_type      <fct> electric_bike, electric_bike, electric_bike, electr…\n$ started_at         <dttm> 2021-09-28 16:07:10, 2021-09-28 14:24:51, 2021-09-…\n$ ended_at           <dttm> 2021-09-28 16:09:54, 2021-09-28 14:40:05, 2021-09-…\n$ start_station_name <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Clark St &…\n$ start_station_id   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"TA13070001…\n$ end_station_name   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ end_station_id     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ start_lat          <dbl> 41.89000, 41.94000, 41.81000, 41.80000, 41.88000, 4…\n$ start_lng          <dbl> -87.68000, -87.64000, -87.72000, -87.72000, -87.740…\n$ end_lat            <dbl> 41.89, 41.98, 41.80, 41.81, 41.88, 41.88, 41.74, 41…\n$ end_lng            <dbl> -87.67, -87.67, -87.72, -87.72, -87.71, -87.74, -87…\n$ member_casual      <fct> casual, casual, casual, casual, casual, casual, cas…\n\n\nThe output indicates that the data set has 5883043 rows, and 13 columns. The start_station_name, start_stattion_id, end_station_name and end_station_id columns appear to have a number of missing values - identified by NA.\nThe extent of the missing information can be assessed by counting the number of NA values in each column.\n\n\nCode\nbike_rides %>%\n  summarise(across(\n    everything(),\n    ~ sum(is.na(.x))\n  )) %>%\n  pivot_longer(\n    cols = everything(),\n    names_to = \"Column\",\n    values_to = \"Missing Count\"\n  )\n\n\n\n\n\nTable 1: Missing Values\n\n\nColumn\nMissing Count\n\n\n\n\nride_id\n0\n\n\nrideable_type\n0\n\n\nstarted_at\n0\n\n\nended_at\n0\n\n\nstart_station_name\n884365\n\n\nstart_station_id\n884363\n\n\nend_station_name\n946303\n\n\nend_station_id\n946303\n\n\nstart_lat\n0\n\n\nstart_lng\n0\n\n\nend_lat\n5727\n\n\nend_lng\n5727\n\n\nmember_casual\n0\n\n\n\n\n\n\n\nTable 1 indicates a significant number of records are missing end and start station name and id. End station location information is also missing small number of records. All other columns have complete data.\n\n\nCode\nbike_rides %>%\n  mutate(\n    missing_start = is.na(start_station_name),\n    missing_end = is.na(end_station_name)\n  ) %>%\n  summarise(\n    \"Start Only\" = sum(missing_start & !missing_end),\n    \"End Only\" = sum(missing_end & !missing_start),\n    Both = sum(missing_start & missing_end),\n    \"Rides effected\" = sum(missing_start | missing_end)\n  )\n\n\n\n\n\nTable 2: Missing Values by station type\n\n\nStart Only\nEnd Only\nBoth\nRides effected\n\n\n\n\n376594\n438532\n507771\n1322897\n\n\n\n\n\n\n\nTable 2 indicates that 22.49% of all rides are missing data for at least one docking station. This represents significant number of data points, and should be checked to determine whether this is an error or there have been systematic changes made.\n\n\nCode\nbike_rides %>%\n  summarise(\n    start_lat = range(start_lat, na.rm = TRUE),\n    start_lng = range(start_lng, na.rm = TRUE),\n    end_lat = range(end_lat, na.rm = TRUE),\n    end_lng = range(end_lng, na.rm = TRUE)\n  )\n\n\n\n\n\nTable 3: Latitude and Longitude ranges\n\n\nstart_lat\nstart_lng\nend_lat\nend_lng\n\n\n\n\n41.64000\n-87.84000\n41.39\n-88.97\n\n\n45.63503\n-73.79648\n42.37\n-87.50\n\n\n\n\n\n\n\nThe maximum start longitude and latitude values listed in Table 3 are significantly different to the remaining values. This suggests some rides may have originated outside the Chicago metropolitan area serviced by Cyclistic.\nIt appears that some latitude and longitude values may have been rounded to two significant digits. Comparing the value to itself rounded to 2 decimal places identifies potentially truncated values. Clamping the coordinates in this way means actual locations can be anywhere within 1 square kilometre area centred on the given grid location.\n\n\nCode\nbike_rides %>%\n  group_by(Missing = is.na(start_station_id)) %>%\n  summarise(\n    Latitude = sum(start_lat == round(start_lat, 2), na.rm = TRUE),\n    Longitude = sum(start_lng == round(start_lng, 2), na.rm = TRUE)\n  )\n\n\n\n\n\nTable 4: Clipped coordinates and missing start station name\n\n\nMissing\nLatitude\nLongitude\n\n\n\n\nFALSE\n78535\n78530\n\n\nTRUE\n884363\n884363\n\n\n\n\n\n\n\nComparing Table 1 with Table 4 indicates the count of start stations with missing names is the same as those which have rounded coordinates.\n\n\nCode\nbike_rides %>%\n  group_by(Missing = is.na(end_station_id)) %>%\n  summarise(\n    Latitude = sum(end_lat == round(end_lat, 2), na.rm = TRUE),\n    Longitude = sum(end_lng == round(end_lng, 2), na.rm = TRUE)\n  )\n\n\n\n\n\nTable 5: Clipped coordinates and missing end station name\n\n\nMissing\nLatitude\nLongitude\n\n\n\n\nFALSE\n71004\n71002\n\n\nTRUE\n940576\n940576\n\n\n\n\n\n\n\nComparing Table 1 with Table 5 indicates the combined count of end stations with missing latitude and longitude and those with rounded coordinates matches the count of missing end station names.\nThis suggests that there is a systemic reason for the missing data, rather than error. It seems likely the location data has been anonymised to protect riders privacy. This needs to be verified with Cyclistics data collection team.\nThe ride duration and other information appear plausible and the lack of location data does not impact analysis of this data. Records with missing location information will be retained but filtered for any analysis which depends on accurate location.\nWhile the majority of rounded coordinates occur where station names are missing approximately 8% are for stations which are named. These need to be checked during cleaning.\n\n\nCode\nbike_rides %>%\n  summarise(\n    start_range = range(started_at),\n    end_range = range(ended_at)\n  )\n\n\n\n\n\nTable 6: Ride start and end date ranges\n\n\nstart_range\nend_range\n\n\n\n\n2021-09-01 00:00:06\n2021-09-01 00:00:41\n\n\n2022-08-31 23:59:39\n2022-09-06 21:49:04\n\n\n\n\n\n\n\nTable 6 indicates the dataset includes rides which finished after August 2022.\n\n\n\nIn total 6431 rides are active at midnight on 31 August 2022. Of these, 48 rides are still active at 9.00am on 1 September 2022. As these overnight rides are excluded from the start of the data set, I’ve opted to retain rides which completed prior to 9.00am to ensure this group of riders is not under represented.\n\n\nData Cleaning\n\nMissing end station coordinates\nThe end stations with missing name and coordinates are addressed first.\n\n\nCode\nno_end_coords <- bike_rides %>%\n  filter(is.na(end_lat), is.na(end_lng))\n\nno_end_coords %>%\n  select(\n    -ride_id,\n    -starts_with(\"start_\")\n  ) %>%\n  head()\n\n\n\n\n\nTable 7: Missing end station coordinates\n\n\n\n\n\n\n\n\n\n\n\n\nrideable_type\nstarted_at\nended_at\nend_station_name\nend_station_id\nend_lat\nend_lng\nmember_casual\n\n\n\n\nclassic_bike\n2021-09-21 15:09:23\n2021-09-21 16:40:03\nNA\nNA\nNA\nNA\ncasual\n\n\nclassic_bike\n2021-09-26 08:32:12\n2021-09-26 11:50:59\nNA\nNA\nNA\nNA\ncasual\n\n\nclassic_bike\n2021-09-04 13:52:02\n2021-09-04 17:21:15\nNA\nNA\nNA\nNA\ncasual\n\n\nclassic_bike\n2021-09-22 10:01:36\n2021-09-23 11:01:27\nNA\nNA\nNA\nNA\ncasual\n\n\nclassic_bike\n2021-09-10 22:48:46\n2021-09-11 23:48:39\nNA\nNA\nNA\nNA\ncasual\n\n\nclassic_bike\n2021-09-15 01:53:24\n2021-09-16 02:53:18\nNA\nNA\nNA\nNA\ncasual\n\n\n\n\n\n\n\nThe preview of these rides contains several rides which extend for more than a day. Cyclistic treat bikes unlocked for more than 24 hours as stolen. These rides are likely to be bikes that have been reported stolen and not physically docked at the ride termination time.\n\n\nCode\nno_end_coords %>%\n  mutate(member_casual = recode(\n    member_casual,\n    \"member\" = \"Member\", \"casual\" = \"Casual\"\n  )) %>%\n  group_by(member_casual) %>%\n  summarise(triptime = as.numeric(started_at %--% ended_at, units = \"days\")) %>%\n  ggplot(aes(triptime, fill = member_casual)) +\n  geom_histogram(binwidth = 1) +\n  guides(fill = \"none\") +\n  facet_grid(rows = vars(member_casual)) +\n  labs(\n    title = \"Rides with missing end coordinates by ride type\",\n    x = \"Trip Duration in Days\",\n    y = \"Rides\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nThe plot shows that around 5000 of the 5727 rides terminated after more than 24 hours. Notably casual rides are the biggest contributor.\n\n\nCyclistic operational rides\nA list of stations that were In-Service between September 2021 and August 2022 was extracted from a dataset maintained by City of Chicago. The dataset for the period of interest contains over 35 million rows recording the status of each docking station at hour intervals.\nDue to the size of the dataset the processed listing of stations is used in this analysis.\n\n\nCode\nactive_stations <- read_csv(\n  \"data/processed/stations_in_use.csv\",\n  show_col_types = FALSE\n)\n\nactive_stations %>%\n  slice_sample(n = 6) %>%\n  select(-id)\n\n\n\n\n\nTable 8: Stations recorded as in-service\n\n\ntimestamp\nstation_name\nlatitude\nlongitude\n\n\n\n\n2021-10-14 21:25:35\nCentral Park Ave & Ohio St\n41.89187\n-87.71639\n\n\n2022-07-07 14:15:27\nPublic Rack - Franklin Park\n41.86149\n-87.73340\n\n\n2021-08-31 05:05:35\nN Damen Ave & W Chicago Ave\n41.89581\n-87.67852\n\n\n2021-08-31 05:05:35\nHomewood Ave & 115th St\n41.68460\n-87.67071\n\n\n2022-05-17 20:35:40\nBensley Ave & 103rd St\n41.70840\n-87.56319\n\n\n2021-08-31 05:05:35\nLincoln Ave & Fullerton Ave\n41.92591\n-87.64926\n\n\n\n\n\n\n\nA random sample of stations from the dataset is shown in Table 8. The timestamp indicates the first time a station appears as In-Service in the original dataset.\nThe active stations dataset is used to identify stations that were not listed as publicly available.\n\n\nCode\nunlisted_start <- bike_rides %>%\n  anti_join(\n    active_stations,\n    by = c(\"start_station_name\" = \"station_name\")\n  ) %>%\n  select(\n    station_name = start_station_name,\n    station_id = start_station_id\n  )\n\nunlisted_end <- bike_rides %>%\n  anti_join(\n    active_stations,\n    by = c(\"end_station_name\" = \"station_name\")\n  ) %>%\n  select(\n    station_name = end_station_name,\n    station_id = end_station_id\n  )\n\nunlisted_stations <- unlisted_start %>%\n  bind_rows(unlisted_end) %>%\n  drop_na(station_name, station_id) %>%\n  group_by(station_name, station_id) %>%\n  summarise(count = n())\n\nunlisted_stations\n\n\n\n\n\nTable 9: Unlisted stations\n\n\n\n\n\n\n\nstation_name\nstation_id\ncount\n\n\n\n\nBase - 2132 W Hubbard\nHubbard Bike-checking (LBS-WH-TEST)\n1182\n\n\nBase - 2132 W Hubbard Warehouse\nHubbard Bike-checking (LBS-WH-TEST)\n963\n\n\nBissell St & Armitage Ave - Charging\nBissell St & Armitage Ave - Charging\n38\n\n\nBissell St & Armitage Ave - Charging\nchargingstx1\n2\n\n\nDIVVY CASSETTE REPAIR MOBILE STATION\nDIVVY CASSETTE REPAIR MOBILE STATION\n8\n\n\nHastings WH 2\nHastings WH 2\n5\n\n\nLincoln Ave & Roscoe St - Charging\nLincoln Ave & Roscoe St - Charging\n6\n\n\nNewHastings\n2059 Hastings Warehouse Station\n47\n\n\nPawel Bialowas - Test- PBSC charging station\nPawel Bialowas - Test- PBSC charging station\n2\n\n\nPublic Rack - Kedzie Ave & 62nd Pl\n1038\n1\n\n\nThroop/Hastings Mobile Station\nThroop/Hastings Mobile Station\n3\n\n\nWEST CHI-WATSON\nDIVVY 001\n21\n\n\nWEST CHI-WATSON\nDIVVY 001 - Warehouse test station\n4\n\n\nWestChi\nDIVVY 001 - Warehouse test station\n6\n\n\nWilton Ave & Diversey Pkwy - Charging\nWilton Ave & Diversey Pkwy - Charging\n38\n\n\n\n\n\n\n\nTable 9 summarises stations which appear in bike_rides without a corresponding match in the active_stations dataset.\nThe majority of stations in the table appear to have an operational function. Those ending with “- Charging” appear to be associated with testing of new charging stations prior to the company publicly announcing their availability.\n\n\nRemoving identified problems\nBefore proceeding with further manipulation and cleaning, the observations with identified problems should be removed. This is done using dplyr::anti_join() to filter the bike_rides dataset removing items matching those found in the unlisted_stations and no_end_coords data.frames.\n\n\nCode\nbike_rides <- bike_rides %>%\n  anti_join(\n    unlisted_stations,\n    by = c(\"start_station_name\" = \"station_name\")\n  ) %>%\n  anti_join(\n    unlisted_stations,\n    by = c(\"end_station_name\" = \"station_name\")\n  ) %>%\n  anti_join(\n    no_end_coords,\n    by = \"ride_id\"\n  )\n\nbike_rides %>%\n  slice_sample(n = 6)\n\n\n\n\n\nTable 10: Sample of cleaned data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nride_id\nrideable_type\nstarted_at\nended_at\nstart_station_name\nstart_station_id\nend_station_name\nend_station_id\nstart_lat\nstart_lng\nend_lat\nend_lng\nmember_casual\n\n\n\n\n4A633974C0BDB7AC\nclassic_bike\n2022-08-11 17:09:12\n2022-08-11 17:19:35\nUniversity Ave & 57th St\nKA1503000071\nKimbark Ave & 53rd St\nTA1309000037\n41.79148\n-87.59986\n41.79957\n-87.59475\ncasual\n\n\n29BB7E99AED8F3F0\nelectric_bike\n2021-10-19 12:25:16\n2021-10-19 12:29:53\n900 W Harrison St\n13028\nSangamon St & Washington Blvd\n13409\n41.87479\n-87.64978\n41.88303\n-87.65107\nmember\n\n\n7CC19BAD6C199498\nelectric_bike\n2021-10-25 19:58:31\n2021-10-25 20:08:18\nWilton Ave & Diversey Pkwy\nTA1306000014\nBroadway & Waveland Ave\n13325\n41.93244\n-87.65281\n41.94908\n-87.64855\nmember\n\n\nA6E2C906370DDEA6\nelectric_bike\n2022-07-20 15:20:28\n2022-07-20 15:31:40\nClark St & Elm St\nTA1307000039\nNA\nNA\n41.90262\n-87.63180\n41.89000\n-87.65000\ncasual\n\n\n1F32E534D31CC114\nclassic_bike\n2022-08-01 13:12:18\n2022-08-01 13:29:00\nLaramie Ave & Gladys Ave\n543\nCicero Ave & Flournoy St\n16912\n41.87581\n-87.75529\n41.87213\n-87.74662\ncasual\n\n\n08BD94378025058A\nclassic_bike\n2022-08-03 17:58:12\n2022-08-03 18:11:51\nClark St & Ida B Wells Dr\nTA1305000009\nSangamon St & Lake St\nTA1306000015\n41.87593\n-87.63058\n41.88578\n-87.65102\nmember\n\n\n\n\n\n\n\nTable 10 shows a sample of the dataset after initial cleaning.\n\n\nRide duration\n\nAdding Ride Duration, Time and Day of Week\nTo add analysis calculated columns for the length of ride, the hour the ride started and the day of week are added to the dataset.\n\n\nCode\nbike_rides <- bike_rides %>%\n  mutate(\n    ride_int = started_at %--% ended_at,\n    ride_time = as.duration(ride_int),\n    hour = hour(started_at),\n    day = wday(started_at, label = TRUE),\n    .before = start_station_name\n  )\n\nbike_rides %>%\n  select(-ride_id, -ride_int) %>%\n  slice_sample(n = 6)\n\n\n\n\n\nTable 11: Sample of rides with duration\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrideable_type\nstarted_at\nended_at\nride_time\nhour\nday\nstart_station_name\nstart_station_id\nend_station_name\nend_station_id\nstart_lat\nstart_lng\nend_lat\nend_lng\nmember_casual\n\n\n\n\nclassic_bike\n2022-08-31 14:51:47\n2022-08-31 15:09:00\n1033s (~17.22 minutes)\n14\nWed\nClark St & Winnemac Ave\nTA1309000035\nMontrose Harbor\nTA1308000012\n41.97335\n-87.66786\n41.96398\n-87.63818\ncasual\n\n\nclassic_bike\n2021-09-15 16:37:58\n2021-09-15 16:48:35\n637s (~10.62 minutes)\n16\nWed\nClark St & Elm St\nTA1307000039\nClinton St & Washington Blvd\nWL-012\n41.90297\n-87.63128\n41.88338\n-87.64117\nmember\n\n\nclassic_bike\n2022-04-10 18:09:29\n2022-04-10 18:15:02\n333s (~5.55 minutes)\n18\nSun\nDuSable Lake Shore Dr & Monroe St\n13300\nField Blvd & South Water St\n15534\n41.88096\n-87.61674\n41.88635\n-87.61752\nmember\n\n\nclassic_bike\n2022-07-02 14:26:46\n2022-07-02 14:29:40\n174s (~2.9 minutes)\n14\nSat\nDuSable Lake Shore Dr & North Blvd\nLF-005\nClark St & North Ave\n13128\n41.91172\n-87.62680\n41.91197\n-87.63194\nmember\n\n\ndocked_bike\n2021-09-03 14:51:56\n2021-09-03 15:22:12\n1816s (~30.27 minutes)\n14\nFri\nStreeter Dr & Grand Ave\n13022\nSheffield Ave & Wrightwood Ave\nTA1309000023\n41.89228\n-87.61204\n41.92871\n-87.65383\ncasual\n\n\nelectric_bike\n2022-07-20 12:20:32\n2022-07-20 12:42:28\n1316s (~21.93 minutes)\n12\nWed\nTheater on the Lake\nTA1308000001\nLakefront Trail & Bryn Mawr Ave\n15576\n41.92625\n-87.63100\n41.98404\n-87.65228\nmember\n\n\n\n\n\n\n\nTable 11 shows a sample of the resulting dataset with added columns.\nMinimum and maximum ride times can now be checked for plausibility.\n\n\nCode\nbike_rides %>%\n  summarise(\n    Minimum = min(ride_time) / 3600,\n    Maximum = max(ride_time) / 3600\n  )\n\n\n\n\n\nTable 12: Summary of ride duration (hours)\n\n\nMinimum\nMaximum\n\n\n\n\n-2.290278\n678.4169\n\n\n\n\n\n\n\nRides with negative duration should not occur, so this needs to be checked and corrected.\n\n\nAddressing negative ride durations\n\n\nCode\nbike_rides %>%\n  group_by(\n    month = floor_date(as.Date(started_at), \"month\")\n  ) %>%\n  summarise(\n    nrt = mean(ride_time < 0) * 100\n  ) %>%\n  ggplot(aes(month, nrt)) +\n  geom_col() +\n  theme_minimal() +\n  labs(\n    title = \"Rides with negative duration\",\n    x = \"Month\",\n    y = \"Percentage of Rides\"\n  )\n\n\n\n\n\nThe plot indicates that the precentage rides with negative ride durations is around three times higher in November than the next highest month - September.\n\n\nCode\nbike_rides %>%\n  filter(month(started_at) == 11) %>%\n  group_by(\"Day\" = day(started_at)) %>%\n  summarise(\"Percent Negative\" = mean(ride_time < 0) * 100) %>%\n  filter(`Percent Negative` > 0)\n\n\n\n\n\nTable 13: Days in November 2021 with negative ride time\n\n\nDay\nPercent Negative\n\n\n\n\n7\n0.2781276\n\n\n\n\n\n\n\nAll rides with negative duration in November occurred on the 7th.\n\n\nCode\nbike_rides %>%\n  filter(\n    month(started_at) == 11,\n    day(started_at) == 7\n  ) %>%\n  group_by(Hour = hour(started_at)) %>%\n  summarise(\n    \"Percent Negative\" = mean(ride_time < 0) * 100,\n    Count = sum(ride_time < 0)\n  ) %>%\n  filter(`Percent Negative` > 0)\n\n\n\n\n\nTable 14: Negative ride duration by hour\n\n\nHour\nPercent Negative\nCount\n\n\n\n\n1\n10.51587\n53\n\n\n\n\n\n\n\nTable 14 shows that all negative ride durations on 7th November were taken between 1.00am and 2.00am. This coincides with the end of daylight savings in Chicago. At 2.00am clocks went back one hour to 1.00am.\nRide start and end timestamp values in the dataset do not include timezone information. Timestamps between 1.00am and 2.00am could refer to either Central Daylight Time or Central Standard Time meaning there is an ambiguity which is very difficult to resolve.\nThe negative duration of rides which start and end between 1.00am and 2.00am can be resolved by adding 60 minutes. However the ambiguity of the rides which have one end point in this time range remains.\nI recommend that timezone be recorded as part of the timestamp in future to avoid these issues.\nFor the present analysis I’ve chosen to correct the negative timestamps between 1.00am and 2.00am and to leave the ambiguous timestamps unaltered.\n\n\nCode\nbike_rides <- bike_rides %>%\n  mutate(ride_time = if_else(\n    (ride_time < 0) & (date(started_at) == date(\"2021-11-07\")),\n    ride_time + 3600,\n    ride_time\n  ))\n\n\n\n\nOther ride duration issues\nThe Cyclistic website indicates that rides of less than 60 seconds have been removed from the dataset. Cyclistic also state that if rides exceed 24 hours the bike is treated as stolen and the user is fined $1200.\n\n\nCode\nbike_rides <- bike_rides %>%\n  filter(ride_time >= 60, ride_time <= 21600)\n\nbike_rides %>%\n  group_by(member_casual, rideable_type) %>%\n  summarise(\n    median = as.numeric(median(ride_time), units = \"secs\"),\n    mean = exp(mean(log(ride_time))),\n    sd = exp(sd(log(ride_time))),\n    iqr = IQR(ride_time),\n    outliers = quantile(ride_time, 0.75) + iqr * 1.5\n  )\n\n\n`summarise()` has grouped output by 'member_casual'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmember_casual\nrideable_type\nmedian\nmean\nsd\niqr\noutliers\n\n\n\n\nmember\nclassic_bike\n576\n580.8936\n2.164365\n656\n1978s (~32.97 minutes)\n\n\nmember\nelectric_bike\n517\n523.0511\n2.171498\n579\n1753.5s (~29.23 minutes)\n\n\ncasual\nclassic_bike\n907\n952.9159\n2.380691\n1101\n3287.5s (~54.79 minutes)\n\n\ncasual\ndocked_bike\n1664\n1733.8565\n2.455082\n2152\n6350s (~1.76 hours)\n\n\ncasual\nelectric_bike\n722\n742.7065\n2.280275\n836\n2517s (~41.95 minutes)\n\n\n\n\n\n\n\n\nCode\nn3 <- round(nrow(bike_rides) * 0.001, 0)\n\nbike_rides %>%\n  slice_max(ride_time, n = n3) %>%\n  summarise(\n    n = n(),\n    Min = min(ride_time) / 3600,\n    Max = max(ride_time) / 3600\n  )\n\n\n\n\n\n\nn\nMin\nMax\n\n\n\n\n5759\n3.546111\n5.999444"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Google Data Analytics Certificate Capstone\n\n\nAn analysis of historical Divvy Bikes ride data to identify differences in user cohort behaviour.\n\n\n\n\n\n\nOct 3, 2022\n\n\n\n\n\n\nNo matching items"
  }
]